Pewnie! Oto przykÅ‚adowy plik `README.md` dla Twojego projektu rozpoznawania gestÃ³w dÅ‚oni przy uÅ¼yciu sieci neuronowej i danych z plikÃ³w `.csv`, oparty na bibliotece Keras i MediaPipe:


# Uruchomienie programu (w srodwisku wirtualnym)
Linux/ mac: (wirtualnie)
python3 -m venv venv
source venv/bin/activate

# instalacja niezbednych bibliotek 
pip install -r requirements.txt


# ğŸ¤– Hand Gesture Recognition with Neural Network

Projekt rozpoznawania gestÃ³w dÅ‚oni w czasie rzeczywistym przy uÅ¼yciu sieci neuronowej i danych przestrzennych punktÃ³w dÅ‚oni (MediaPipe). Model uczy siÄ™ rozpoznawaÄ‡ rÃ³Å¼ne gesty rÄ™ki na podstawie wspÃ³Å‚rzÄ™dnych 3D i klasyfikuje je do jednej z kilkunastu zdefiniowanych kategorii.

## ğŸ§  O projekcie

Celem projektu jest stworzenie prostego, ale skutecznego systemu rozpoznawania gestÃ³w, ktÃ³ry moÅ¼e byÄ‡ uÅ¼ywany do:

- sterowania aplikacjami,
- interfejsÃ³w uÅ¼ytkownika bezdotykowych (touchless UI),
- wsparcia dla osÃ³b z niepeÅ‚nosprawnoÅ›ciami,
- zabawy lub gier opartych na gestach.

Model zostaÅ‚ wytrenowany na danych zapisanych w plikach `.csv`, ktÃ³re zawierajÄ… 63 cechy (21 punktÃ³w dÅ‚oni * 3 wspÃ³Å‚rzÄ™dne: x, y, z).

## ğŸ“ Struktura projektu

```

gesty/
â”œâ”€â”€ model/                      # Zapisany model .keras
â”œâ”€â”€ training\_data/             # Pliki CSV z danymi dla kaÅ¼dego gestu
â”‚   â”œâ”€â”€ data\_fist.csv
â”‚   â”œâ”€â”€ data\_open.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ train\_model.py         # Skrypt do trenowania modelu
â”œâ”€â”€ gesture\_predictor.py       # (opcjonalnie) Klasyfikator do predykcji w czasie rzeczywistym
â””â”€â”€ README.md                  # Niniejszy plik

````

## ğŸ§ª Gesty do rozpoznania

Model rozpoznaje nastÄ™pujÄ…ce gesty dÅ‚oni:

1. ğŸ‘Š PiÄ™Å›Ä‡ (`fist`)
2. âœ‹ Otwarta dÅ‚oÅ„ (`open`)
3. âœŒï¸ ZwyciÄ™stwo (`victory`)
4. ğŸ¤˜ Rock (`rock`)
5. â˜ï¸ WskazujÄ…cy palec (`point`)
6. ğŸ–– Spock (`Spock`)
7. ğŸ¤™ Call me (`CallMe`)
8. âœŒï¸âœŒï¸ Dwa palce wskazujÄ…ce (`TwoFingerPoint`)
9. ğŸ‘† Kciuk do palca wskazujÄ…cego (`ThumbToPoint`)
10. ğŸ‘‰ Kciuk do Å›rodkowego (`ThumbToMiddle`)
11. ğŸ–• Åšrodkowy palec (`middleFinger`)

## ğŸš€ Jak uruchomiÄ‡

1. **Zainstaluj zaleÅ¼noÅ›ci:**

```bash
pip install -r requirements.txt
````

2. **Trenuj model:**

```bash
python utils/train_model.py
```

3. **Model zostanie zapisany do folderu `model/gesture_model.keras`.**

## ğŸ› ï¸ Technologie

* Python 3.11+
* TensorFlow / Keras
* NumPy, Pandas
* MediaPipe (do generowania danych gestÃ³w)
* scikit-learn (do podziaÅ‚u danych)

## âœ… PrzykÅ‚adowy wynik

```
Liczba prÃ³bek: 5500, liczba cech: 63  
Liczba klas: 11  
Test loss: 0.0553, Test accuracy: 0.9817  
Model wytrenowany i zapisany do model/gesture_model.keras
```

## ğŸ’¡ PomysÅ‚y na rozwÃ³j

* Dodanie kamery i integracja z MediaPipe w czasie rzeczywistym
* WiÄ™cej klas gestÃ³w (np. alfabet migowy)
* Eksport modelu do TensorFlow Lite do uÅ¼ycia na urzÄ…dzeniach mobilnych
* Interfejs graficzny (GUI) do demonstracji gestÃ³w

## ğŸ“„ Licencja

Projekt edukacyjny, open-source â€” feel free to fork & modify âœŒï¸

---

ğŸ§  Autor: \[Twoje imiÄ™/nick]
ğŸ“… Data ostatniej aktualizacji: czerwiec 2025

```

---

JeÅ›li chcesz, mogÄ™ teÅ¼ przygotowaÄ‡ wersjÄ™ po angielsku, dodaÄ‡ grafikÄ™ lub diagram dziaÅ‚ania. Daj znaÄ‡!
```
