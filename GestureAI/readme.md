#  Rozpoznawanie GestÃ³w DÅ‚oni z SieciÄ… NeuronowÄ… (TensorFlow + MediaPipe)

Projekt ten umoÅ¼liwia rozpoznawanie gestÃ³w dÅ‚oni na podstawie danych 3D punktÃ³w z MediaPipe i klasyfikuje je za pomocÄ… sieci neuronowej. Uczy siÄ™ na danych z plikÃ³w CSV i moÅ¼e byÄ‡ rozszerzony do obsÅ‚ugi gestÃ³w w czasie rzeczywistym.


---

##  Szybki start

### 1. UtwÃ³rz i aktywuj Å›rodowisko wirtualne (Linux/macOS):
python3 -m venv venv
source venv/bin/activate

### 2. Zainstaluj zaleÅ¼noÅ›ci:
pip install -r requirements.txt

### 3. Wytrenuj model:
python utils/train_model.py

Model zostanie zapisany jako: model/gesture_model.keras

â¸»

## O projekcie
	â€¢	 Uczy siÄ™ 63 cech (21 punktÃ³w dÅ‚oni Ã— 3 wymiary: x, y, z)
	â€¢	 Dane treningowe w formacie CSV (training_data/)
	â€¢	 MoÅ¼liwoÅ›Ä‡ Å‚atwego rozszerzenia o nowy gest
	â€¢	 Zaprojektowane z myÅ›lÄ… o kontroli ruchem, grach i interfejsach bezdotykowych

â¸»

## Rozpoznawane gesty
```bash
Nazwa	Opis
fist	ğŸ‘Š PiÄ™Å›Ä‡
open	âœ‹ Otwarta dÅ‚oÅ„
victory	âœŒï¸ ZwyciÄ™stwo
rock	ğŸ¤˜ Rock
point	â˜ï¸ WskazujÄ…cy palec
Spock	ğŸ–– Spock
CallMe	ğŸ¤™ Call me
TwoFingerPoint	âœŒï¸âœŒï¸ Dwa palce wskazujÄ…ce
ThumbToPoint	ğŸ‘† Kciuk â†’ wskazujÄ…cy
ThumbToMiddle	ğŸ‘‰ Kciuk â†’ Å›rodkowy
middleFinger	ğŸ–• Åšrodkowy palec
```

â¸»

ğŸ—‚ï¸ Struktura projektu
```bash
.
â”œâ”€â”€ model/
â”‚   â””â”€â”€ gesture_model.keras
â”œâ”€â”€ training_data/
â”‚   â”œâ”€â”€ data_fist.csv
â”‚   â”œâ”€â”€ data_open.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ collect_data.py
â”‚   â”œâ”€â”€ gestures_control.py
â”‚   â””â”€â”€ train_model.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

â¸»

## Pliki i funkcje

	â€¢	collect_data.py â€“ Zbieranie punktÃ³w dÅ‚oni do plikÃ³w .csv
	â€¢	train_model.py â€“ Trening modelu Keras
	â€¢	gestures_control.py â€“ Wykrywanie gestÃ³w i kontrolowanie kursora/myszy

â¸»

## PrzykÅ‚ad wynikÃ³w
```bash
Liczba prÃ³bek: 5500
Liczba cech: 63
Liczba klas: 11
Test accuracy: 0.9817
Model zapisany do model/gesture_model.keras
```


â¸»

## MoÅ¼liwoÅ›ci rozwoju
```bash
	â€¢	Dodanie rozpoznawania gestÃ³w na Å¼ywo z kamery
	â€¢	Eksport modelu do TensorFlow Lite (np. na Raspberry Pi)
	â€¢	Rozszerzenie o alfabet migowy (ASL)
	â€¢	Stworzenie GUI do testowania
```
â¸»
